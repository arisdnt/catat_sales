# Analisis Big Data: Pagination dan Search di Halaman Toko

## Analisis Masalah Saat Ini

### Struktur Database (berdasarkan mulai.sql)

**Tabel toko:**
- `id_toko` (PK)
- `id_sales` (FK ke sales)
- `nama_toko`
- `kecamatan`
- `kabupaten`
- `no_telepon`
- `link_gmaps`
- `status_toko`

**Relasi terkait:**
- 1 sales : N toko
- 1 toko : N pengiriman
- 1 toko : N penagihan

### Implementasi Saat Ini

**Frontend (app/dashboard/master-data/toko/page.tsx):**
1. Menggunakan `useTokoInfiniteQuery` dengan pagination 50 item
2. Infinite scroll dengan Intersection Observer
3. Filter dan search dilakukan di client-side menggunakan TanStack Table
4. Data di-enrich dengan agregasi barang_terkirim/terbayar/sisa_stok

**Backend API (app/api/toko/route.ts):**
1. Query pagination dengan LIMIT/OFFSET
2. Enrichment data dengan N+1 queries untuk setiap toko
3. Agregasi barang dilakukan untuk setiap record

**Query Hooks (lib/queries/toko.ts):**
1. TanStack Query dengan infinite query
2. Cache stale time 5 menit

## Identifikasi Masalah dengan Big Data

### 1. Performance Issues
- **N+1 Query Problem**: Setiap toko membutuhkan 2 queries tambahan untuk pengiriman dan penagihan
- **Client-side Filtering**: Filter hanya bekerja pada data yang sudah di-load
- **Memory Usage**: Infinite scroll terus menumpuk data di memory browser
- **Heavy Aggregation**: Kalkulasi barang_terkirim/terbayar dilakukan real-time

### 2. Search Limitations
- Search hanya mencari di data yang sudah di-load ke frontend
- Tidak ada server-side search implementation
- Filter kabupaten/kecamatan options terbatas pada data yang sudah di-load

### 3. Scalability Problems
- Enrichment data tidak scalable untuk ribuan toko
- Client-side filtering tidak efisien untuk dataset besar
- Infinite scroll tanpa virtual scrolling akan crash browser

## Solusi Teknis yang Harus Diimplementasikan

### 1. Server-Side Search dan Filtering

**Implementasi di API Route:**
```typescript
// app/api/toko/route.ts
export async function GET(request: NextRequest) {
  const { searchParams } = new URL(request.url)
  const search = searchParams.get('search')
  const sales_id = searchParams.get('sales_id')
  const kabupaten = searchParams.get('kabupaten')
  const kecamatan = searchParams.get('kecamatan')
  
  let query = supabaseAdmin
    .from('toko')
    .select('*')
  
  // Server-side search
  if (search) {
    query = query.or(`nama_toko.ilike.%${search}%,kecamatan.ilike.%${search}%,kabupaten.ilike.%${search}%`)
  }
  
  // Server-side filters
  if (sales_id) query = query.eq('id_sales', sales_id)
  if (kabupaten) query = query.eq('kabupaten', kabupaten)
  if (kecamatan) query = query.eq('kecamatan', kecamatan)
}
```

### 2. Database Optimization

**Buat Indexes untuk Performance:**
```sql
-- Indexes untuk search dan filter
CREATE INDEX idx_toko_nama_search ON toko USING gin(to_tsvector('indonesian', nama_toko));
CREATE INDEX idx_toko_location ON toko(kabupaten, kecamatan);
CREATE INDEX idx_toko_sales ON toko(id_sales);
CREATE INDEX idx_toko_status ON toko(status_toko);

-- Composite index untuk filter kombinasi
CREATE INDEX idx_toko_search_filter ON toko(id_sales, kabupaten, kecamatan, status_toko);
```

**Buat Materialized View untuk Agregasi:**
```sql
-- View untuk agregasi data barang per toko
CREATE MATERIALIZED VIEW mv_toko_aggregates AS
SELECT 
  t.id_toko,
  t.nama_toko,
  t.id_sales,
  s.nama_sales,
  t.kabupaten,
  t.kecamatan,
  t.status_toko,
  COALESCE(SUM(dp.jumlah_kirim), 0) as barang_terkirim,
  COALESCE(SUM(dt.jumlah_terjual), 0) as barang_terbayar,
  COALESCE(SUM(dp.jumlah_kirim), 0) - COALESCE(SUM(dt.jumlah_terjual), 0) as sisa_stok
FROM toko t
LEFT JOIN sales s ON t.id_sales = s.id_sales
LEFT JOIN pengiriman p ON t.id_toko = p.id_toko
LEFT JOIN detail_pengiriman dp ON p.id_pengiriman = dp.id_pengiriman
LEFT JOIN penagihan pen ON t.id_toko = pen.id_toko
LEFT JOIN detail_penagihan dt ON pen.id_penagihan = dt.id_penagihan
GROUP BY t.id_toko, t.nama_toko, t.id_sales, s.nama_sales, t.kabupaten, t.kecamatan, t.status_toko;

-- Index untuk materialized view
CREATE INDEX idx_mv_toko_agg_search ON mv_toko_aggregates USING gin(to_tsvector('indonesian', nama_toko));
CREATE INDEX idx_mv_toko_agg_filter ON mv_toko_aggregates(id_sales, kabupaten, kecamatan, status_toko);

-- Function untuk refresh materialized view
CREATE OR REPLACE FUNCTION refresh_toko_aggregates() RETURNS void AS $$
BEGIN
  REFRESH MATERIALIZED VIEW CONCURRENTLY mv_toko_aggregates;
END;
$$ LANGUAGE plpgsql;
```

### 3. Backend API Improvements

**Update API Route untuk menggunakan Materialized View:**
```typescript
// app/api/toko/route.ts - Optimized version
export async function GET(request: NextRequest) {
  return handleApiRequest(request, async () => {
    const { searchParams } = new URL(request.url)
    const search = searchParams.get('search')
    const sales_id = searchParams.get('sales_id')
    const kabupaten = searchParams.get('kabupaten')
    const kecamatan = searchParams.get('kecamatan')
    const status = searchParams.get('status')
    const page = parseInt(searchParams.get('page') || '1')
    const limit = parseInt(searchParams.get('limit') || '50')
    
    // Use materialized view instead of multiple joins
    let query = supabaseAdmin
      .from('mv_toko_aggregates')
      .select('*')
    
    // Server-side search with full-text search
    if (search) {
      query = query.or(`nama_toko.ilike.%${search}%,kabupaten.ilike.%${search}%,kecamatan.ilike.%${search}%`)
    }
    
    // Apply filters
    if (sales_id) query = query.eq('id_sales', sales_id)
    if (kabupaten) query = query.eq('kabupaten', kabupaten)
    if (kecamatan) query = query.eq('kecamatan', kecamatan)
    if (status === 'active') query = query.eq('status_toko', true)
    
    // Get count for pagination
    const { count } = await query.select('*', { count: 'exact', head: true })
    
    // Apply pagination and ordering
    const { data, error } = await query
      .order('nama_toko')
      .range((page - 1) * limit, page * limit - 1)
    
    return createSuccessResponse({
      data,
      pagination: {
        page,
        limit,
        total: count || 0,
        totalPages: Math.ceil((count || 0) / limit),
        hasNextPage: page * limit < (count || 0),
        hasPrevPage: page > 1
      }
    })
  })
}
```

### 4. Frontend Optimization

**Update Query Hook untuk Server-side Search:**
```typescript
// lib/queries/toko.ts - Enhanced version
export function useTokoInfiniteQuery(
  status?: 'active',
  includeSales?: boolean,
  limit: number = 50,
  search?: string,
  filters?: Record<string, string>
) {
  return useInfiniteQuery({
    queryKey: [...tokoKeys.list({ status, includeSales, search, filters }), 'infinite'],
    queryFn: ({ pageParam = 1 }) => {
      const params = new URLSearchParams({
        page: pageParam.toString(),
        limit: limit.toString(),
        ...(status && { status }),
        ...(includeSales && { include_sales: 'true' }),
        ...(search && { search }),
        ...filters
      })
      
      return apiClient.get(`/api/toko?${params}`) as Promise<PaginatedApiResponse<Toko>>
    },
    getNextPageParam: (lastPage) => {
      const pagination = lastPage.data.pagination
      return pagination.hasNextPage ? pagination.page + 1 : undefined
    },
    staleTime: 1000 * 60 * 2, // Reduce to 2 minutes for fresher search results
    initialPageParam: 1,
  })
}
```

**Update Component untuk Server-side Search:**
```typescript
// app/dashboard/master-data/toko/page.tsx - Enhanced version
export default function TokoTablePage() {
  const [searchQuery, setSearchQuery] = useState('')
  const [filters, setFilters] = useState<Record<string, string>>({})
  const [debouncedSearch] = useDebounce(searchQuery, 500) // Debounce search
  
  const {
    data,
    isLoading,
    fetchNextPage,
    hasNextPage,
    isFetchingNextPage,
    refetch
  } = useTokoInfiniteQuery('active', true, 50, debouncedSearch, filters)
  
  // Reset pagination when search/filter changes
  useEffect(() => {
    refetch()
  }, [debouncedSearch, filters])
  
  // Server-side search handler
  const handleSearchChange = (value: string) => {
    setSearchQuery(value)
  }
  
  // Server-side filter handler
  const handleFilterChange = (key: string, value: string) => {
    setFilters(prev => ({
      ...prev,
      [key]: value === 'all' ? '' : value
    }))
  }
}
```

### 5. Virtual Scrolling Implementation

**Untuk Dataset Sangat Besar (>10K records):**
```typescript
// components/shared/virtual-data-table.tsx
import { useVirtualizer } from '@tanstack/react-virtual'

export function VirtualDataTable({ data, columns, onLoadMore }) {
  const parentRef = useRef<HTMLDivElement>(null)
  
  const virtualizer = useVirtualizer({
    count: data.length,
    getScrollElement: () => parentRef.current,
    estimateSize: () => 60, // Row height
    overscan: 10
  })
  
  // Load more when near end
  useEffect(() => {
    const [lastItem] = [...virtualizer.getVirtualItems()].reverse()
    
    if (!lastItem) return
    
    if (lastItem.index >= data.length - 1 && hasNextPage && !isFetchingNextPage) {
      onLoadMore()
    }
  }, [virtualizer.getVirtualItems(), data.length, hasNextPage, isFetchingNextPage])
  
  return (
    <div ref={parentRef} className="h-[600px] overflow-auto">
      <div style={{ height: `${virtualizer.getTotalSize()}px`, position: 'relative' }}>
        {virtualizer.getVirtualItems().map((virtualItem) => (
          <div
            key={virtualItem.index}
            style={{
              position: 'absolute',
              top: 0,
              left: 0,
              width: '100%',
              height: `${virtualItem.size}px`,
              transform: `translateY(${virtualItem.start}px)`
            }}
          >
            {/* Render row */}
          </div>
        ))}
      </div>
    </div>
  )
}
```

### 6. Caching Strategy

**Implement Redis Caching:**
```typescript
// lib/cache.ts
import Redis from 'ioredis'

const redis = new Redis(process.env.REDIS_URL)

export async function getCachedFilterOptions(type: 'kabupaten' | 'kecamatan' | 'sales') {
  const cacheKey = `filter_options:${type}`
  const cached = await redis.get(cacheKey)
  
  if (cached) {
    return JSON.parse(cached)
  }
  
  // Fetch from database
  let query
  switch (type) {
    case 'kabupaten':
      query = supabaseAdmin.from('toko').select('kabupaten').not('kabupaten', 'is', null)
      break
    case 'kecamatan':
      query = supabaseAdmin.from('toko').select('kecamatan').not('kecamatan', 'is', null)
      break
    case 'sales':
      query = supabaseAdmin.from('sales').select('id_sales, nama_sales').eq('status_aktif', true)
      break
  }
  
  const { data } = await query
  const options = [...new Set(data?.map(item => Object.values(item)[0]))]
  
  // Cache for 1 hour
  await redis.setex(cacheKey, 3600, JSON.stringify(options))
  
  return options
}
```

### 7. Background Jobs untuk Materialized View

**Setup Cron Job atau Trigger:**
```sql
-- Auto-refresh materialized view after data changes
CREATE OR REPLACE FUNCTION trigger_refresh_toko_aggregates()
RETURNS trigger AS $$
BEGIN
  -- Refresh in background
  PERFORM pg_notify('refresh_toko_aggregates', '');
  RETURN NULL;
END;
$$ LANGUAGE plpgsql;

-- Triggers untuk auto-refresh
CREATE TRIGGER refresh_on_pengiriman_change
  AFTER INSERT OR UPDATE OR DELETE ON detail_pengiriman
  FOR EACH STATEMENT
  EXECUTE FUNCTION trigger_refresh_toko_aggregates();

CREATE TRIGGER refresh_on_penagihan_change
  AFTER INSERT OR UPDATE OR DELETE ON detail_penagihan
  FOR EACH STATEMENT
  EXECUTE FUNCTION trigger_refresh_toko_aggregates();
```

## Implementasi Bertahap

### Phase 1: Quick Wins (1-2 hari)
1. Implement server-side search di API route
2. Update frontend untuk menggunakan server-side search
3. Add debouncing untuk search input
4. Create database indexes

### Phase 2: Performance Optimization (3-5 hari)
1. Create materialized view untuk agregasi
2. Update API untuk menggunakan materialized view
3. Implement caching untuk filter options
4. Setup background refresh untuk materialized view

### Phase 3: Advanced Features (1 minggu)
1. Implement virtual scrolling untuk dataset sangat besar
2. Add Redis caching layer
3. Optimize database queries dengan EXPLAIN ANALYZE
4. Add monitoring untuk query performance

### Phase 4: Production Tuning (2-3 hari)
1. Setup database connection pooling
2. Add query result compression
3. Implement CDN untuk static assets
4. Setup application monitoring

## Monitoring dan Metrics

### Key Performance Indicators:
1. **Search Response Time**: Target <200ms
2. **Page Load Time**: Target <500ms untuk 50 records
3. **Memory Usage**: Max 100MB browser memory untuk 1000+ records
4. **Database Query Time**: Target <100ms per query
5. **Cache Hit Ratio**: Target >80% untuk filter options

### Monitoring Tools:
1. Database: PostgreSQL slow query log
2. Application: APM tools (New Relic, DataDog)
3. Frontend: Web Vitals monitoring
4. Caching: Redis monitoring dashboard

## Conclusion

Implementasi solusi ini akan memungkinkan sistem untuk:
- Handle millions of records dengan performance konsisten
- Search dan filter real-time di seluruh dataset
- Maintain responsive UI bahkan dengan dataset besar
- Scale horizontal dengan caching dan background processing

Total estimasi waktu implementasi: 2-3 minggu untuk full solution.